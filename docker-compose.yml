version: "3.9"

services:

  llm_inference:
    build:
      context: ./workspace
      dockerfile: Dockerfile.llm
    container_name: llm_inference_gpu
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - ./workspace:/workspace
      - /dev/xdma0:/dev/xdma0
    working_dir: /workspace
    tty: true
    stdin_open: true
    command: bash
    depends_on:
      fpga_driver:
        condition: service_healthy

  fpga_driver:
    image: ubuntu:20.04
    container_name: fpga_driver
    privileged: true  # Pour accéder à /dev
    devices:
      - /dev/xdma0:/dev/xdma0
    volumes:
      - ./fpga_sim:/driver
    command: bash -c "echo '[FPGA Driver Ready]' && /driver/create_pipe.sh"
    healthcheck:
      test: ["CMD-SHELL", "echo ok"]
      interval: 5s
      timeout: 3s
      retries: 5

  container_monitor:
    image: nicolargo/glances
    container_name: monitor
    ports:
      - "61208:61208"  # Accès web via localhost:61208
    pid: "host"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    restart: always
    command: glances -w
    depends_on:
      - llm_inference
      - fpga_driver
